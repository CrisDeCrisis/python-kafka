# AI Server - Sistema Integrado con LangChain, Ollama y Kafka

Sistema completo de inteligencia artificial que combina **FastAPI**, **LangChain**, **Ollama** y **Apache Kafka** para proporcionar un servidor de IA escalable con capacidades de procesamiento en tiempo real, base de datos vectorial y distribuci√≥n de mensajes.

## üöÄ Caracter√≠sticas Principales

- **üåê API REST Completa**: FastAPI con documentaci√≥n autom√°tica (Swagger/ReDoc)
- **ü§ñ Modelos de IA Locales**: Integraci√≥n nativa con Ollama
- **üß† Base de Datos Vectorial**: ChromaDB para b√∫squeda sem√°ntica y contexto
- **üì° Apache Kafka**: Streaming de respuestas y distribuci√≥n de mensajes
- **‚ö° Respuestas Streaming**: Comunicaci√≥n en tiempo real
- **üîç Health Monitoring**: Verificaci√≥n completa de todos los servicios
- **üìÑ Gesti√≥n de Documentos**: Procesamiento autom√°tico de embeddings
- **üí¨ Contexto Conversacional**: Mantenimiento de historial de conversaciones

## üèóÔ∏è Arquitectura del Sistema

```mermaid
graph TD
    A[Cliente] --> B[FastAPI Server]
    B --> C[LangChain]
    C --> D[Ollama LLM]
    C --> E[ChromaDB]
    B --> F[Kafka Producer]
    F --> G[Kafka Topics]
    G --> H[Kafka Consumer]
    E --> I[Vector Search]
    I --> C
```

## ‚öôÔ∏è Instalaci√≥n y Configuraci√≥n

### üìã Prerrequisitos

- **Python 3.11+**
- **Docker y Docker Compose** (para Kafka)
- **Ollama** instalado y ejecut√°ndose
- **Git** (para clonar el repositorio)

### üîΩ Instalaci√≥n R√°pida

#### 1. Preparar Ollama

```powershell
# Instalar Ollama (Windows)
# Descargar desde: https://ollama.ai/download

# Descargar modelos necesarios
ollama pull phi3:3.8b
ollama pull nomic-embed-text

# Verificar modelos
ollama list
```

#### 2. Configurar Entorno Python

```powershell
# Navegar al directorio del servidor
cd server-python

# Crear entorno virtual
python -m venv .venv

# Activar entorno virtual (Windows)
.venv\Scripts\activate

# Actualizar pip
python -m pip install --upgrade pip

# Instalar dependencias
pip install -r requirements.txt
```

#### 3. Configurar Variables de Entorno

```powershell
# Copiar archivo de configuraci√≥n
copy .env.example .env

# Editar .env si es necesario (valores por defecto funcionan)
```

#### 4. Iniciar Servicios Kafka (Opcional)

```powershell
# Desde el directorio ra√≠z del proyecto
docker-compose up -d

# Verificar servicios
docker-compose ps

# Crear topics de Kafka
cd server-python
python create_kafka_topics.py
```

#### 5. Iniciar el Servidor

```powershell
# M√©todo 1: Script directo
python run.py

# M√©todo 2: Con utilidades
python utils.py start

# M√©todo 3: Desarrollo con recarga
uvicorn app.main:app --host 0.0.0.0 --port 8000 --reload
```

### üåê URLs Importantes

- **API Principal**: http://localhost:8000
- **Documentaci√≥n Swagger**: http://localhost:8000/docs
- **ReDoc**: http://localhost:8000/redoc
- **Kafka UI**: http://localhost:8080 (si Docker est√° ejecut√°ndose)
- **Health Check**: http://localhost:8000/health

## üîó API y Uso del Sistema

### üìö Documentaci√≥n Interactiva

- **Swagger UI**: http://localhost:8000/docs
- **ReDoc**: http://localhost:8000/redoc

### üéØ Endpoints Principales

#### üí¨ Chat y Conversaci√≥n

```powershell
# Chat b√°sico
curl -X POST "http://localhost:8000/chat/" `
  -H "Content-Type: application/json" `
  -d '{"message": "¬øC√≥mo funciona la inteligencia artificial?", "use_context": false, "temperature": 0.7}'

# Chat con contexto vectorial
curl -X POST "http://localhost:8000/chat/" `
  -H "Content-Type: application/json" `
  -d '{"message": "Explica machine learning", "use_context": true, "conversation_id": "conv_123"}'

# Chat streaming en tiempo real
curl -X POST "http://localhost:8000/chat/stream" `
  -H "Content-Type: application/json" `
  -d '{"message": "Escribe un poema sobre la tecnolog√≠a", "use_context": false}'

# Historial de conversaci√≥n
curl "http://localhost:8000/chat/history/conv_123"
```

#### üìÑ Gesti√≥n de Documentos

```powershell
# A√±adir documento al contexto
curl -X POST "http://localhost:8000/documents/" `
  -H "Content-Type: application/json" `
  -d '{"content": "Informaci√≥n importante sobre el proyecto...", "metadata": {"tipo": "documentacion"}, "conversation_id": "conv_123"}'

# Estad√≠sticas de documentos
curl "http://localhost:8000/documents/stats"
```

#### üîç Monitoreo y Salud

```powershell
# Health check general
curl "http://localhost:8000/health/"

# Estado espec√≠fico de Kafka
curl "http://localhost:8000/health/kafka"

# Informaci√≥n de modelos
curl "http://localhost:8000/health/models"

# Informaci√≥n del sistema
curl "http://localhost:8000/"
```

## üì° Integraci√≥n con Apache Kafka

### üéØ Topics Configurados

El sistema crea autom√°ticamente los siguientes topics:

| Topic                    | Descripci√≥n                | Uso                               |
| ------------------------ | -------------------------- | --------------------------------- |
| `ia-responses`           | Respuestas completas de IA | Almacena conversaciones completas |
| `ia-responses-streaming` | Fragmentos streaming       | Chunks en tiempo real             |

### üìù Formato de Mensajes

#### Topic: `ia-responses`

```json
{
  "conversation_id": "conv_123",
  "user_message": "¬øC√≥mo funciona Kafka?",
  "ai_response": "Apache Kafka es una plataforma de streaming distribuida...",
  "context_used": true,
  "metadata": {
    "temperature": 0.7,
    "model": "phi3:3.8b",
    "use_context": true,
    "streaming": false,
    "timestamp": "2025-07-08T10:30:00.000Z"
  }
}
```

#### Topic: `ia-responses-streaming`

```json
{
  "conversation_id": "conv_123",
  "chunk": "Apache Kafka",
  "chunk_index": 0,
  "is_final": false,
  "timestamp": "2025-07-08T10:30:00.000Z",
  "message_type": "streaming_chunk"
}
```

### üîÑ Consumir Mensajes

```powershell
# Usar el script de ejemplo incluido
python kafka_consumer_example.py

# Consumir con kafka-console-consumer (Docker)
docker exec -it kafka kafka-console-consumer `
  --bootstrap-server localhost:9092 `
  --topic ia-responses `
  --from-beginning

# Ver todos los topics disponibles
docker exec -it kafka kafka-topics `
  --bootstrap-server localhost:9092 `
  --list
```

### üñ•Ô∏è Kafka UI - Interfaz Web

Accede a **http://localhost:8080** para:

- üìä **Monitorear Topics**: Ver mensajes en tiempo real
- üìà **Estad√≠sticas**: Throughput, lag, particiones
- ‚öôÔ∏è **Configuraci√≥n**: Gestionar topics y configuraciones
- üîç **B√∫squeda**: Filtrar mensajes por criterios

### ‚ö° Scripts de Utilidad

```powershell
# Verificar conectividad con Kafka
python verify_kafka.py

# Crear topics manualmente
python create_kafka_topics.py

# Cliente consumidor de ejemplo
python kafka_consumer_example.py
```

## üõ†Ô∏è Desarrollo y Arquitectura

### üìÅ Estructura del Proyecto

```
python-kafka/
‚îú‚îÄ‚îÄ üìÑ docker-compose.yml           # Configuraci√≥n de Kafka
‚îú‚îÄ‚îÄ üìÑ README_KAFKA.md             # Documentaci√≥n principal
‚îî‚îÄ‚îÄ server-python/
    ‚îú‚îÄ‚îÄ üìÅ app/                    # C√≥digo principal de la aplicaci√≥n
    ‚îÇ   ‚îú‚îÄ‚îÄ üìÑ main.py             # Aplicaci√≥n FastAPI
    ‚îÇ   ‚îú‚îÄ‚îÄ üìÑ config.py           # Configuraci√≥n centralizada
    ‚îÇ   ‚îú‚îÄ‚îÄ üìÑ models.py           # Modelos Pydantic
    ‚îÇ   ‚îú‚îÄ‚îÄ üìÑ dependencies.py     # Inyecci√≥n de dependencias
    ‚îÇ   ‚îú‚îÄ‚îÄ üìÑ logging_config.py   # Configuraci√≥n de logs
    ‚îÇ   ‚îú‚îÄ‚îÄ üìÅ api/                # Endpoints REST
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ üìÑ chat.py         # Endpoints de chat
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ üìÑ documents.py    # Gesti√≥n de documentos
    ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ üìÑ health.py       # Health checks
    ‚îÇ   ‚îî‚îÄ‚îÄ üìÅ services/           # L√≥gica de negocio
    ‚îÇ       ‚îú‚îÄ‚îÄ üìÑ chat_service.py     # Orquestador principal
    ‚îÇ       ‚îú‚îÄ‚îÄ üìÑ llm_service.py      # Integraci√≥n Ollama
    ‚îÇ       ‚îú‚îÄ‚îÄ üìÑ embedding_service.py # Procesamiento embeddings
    ‚îÇ       ‚îú‚îÄ‚îÄ üìÑ vector_db_service.py # ChromaDB
    ‚îÇ       ‚îî‚îÄ‚îÄ üìÑ kafka_service.py    # Integraci√≥n Kafka
    ‚îú‚îÄ‚îÄ üìÅ chroma_db/             # Base de datos vectorial
    ‚îú‚îÄ‚îÄ üìÅ logs/                  # Archivos de log
    ‚îú‚îÄ‚îÄ üìÑ requirements.txt       # Dependencias Python
    ‚îú‚îÄ‚îÄ üìÑ .env.example          # Variables de entorno
    ‚îú‚îÄ‚îÄ üìÑ run.py                # Punto de entrada
    ‚îú‚îÄ‚îÄ üìÑ utils.py              # Utilidades de desarrollo
    ‚îú‚îÄ‚îÄ üìÑ diagnose.py           # Script de diagn√≥stico
    ‚îú‚îÄ‚îÄ üìÑ verify_kafka.py       # Verificaci√≥n Kafka
    ‚îú‚îÄ‚îÄ üìÑ create_kafka_topics.py # Creaci√≥n de topics
    ‚îú‚îÄ‚îÄ üìÑ kafka_consumer_example.py # Cliente consumidor
    ‚îî‚îÄ‚îÄ üìÑ client_example.py     # Cliente de prueba
```

### ‚öôÔ∏è Configuraciones Disponibles

| Variable                   | Descripci√≥n             | Valor por Defecto            |
| -------------------------- | ----------------------- | ---------------------------- |
| `APP_NAME`                 | Nombre de la aplicaci√≥n | `"AI Server with LangChain"` |
| `DEBUG`                    | Modo debug              | `false`                      |
| `HOST`                     | Host del servidor       | `"0.0.0.0"`                  |
| `PORT`                     | Puerto del servidor     | `8000`                       |
| `OLLAMA_BASE_URL`          | URL de Ollama           | `"http://localhost:11434"`   |
| `LLM_MODEL`                | Modelo de lenguaje      | `"phi3:3.8b"`                |
| `EMBEDDING_MODEL`          | Modelo de embeddings    | `"nomic-embed-text"`         |
| `CHROMA_PERSIST_DIRECTORY` | Directorio ChromaDB     | `"./chroma_db"`              |
| `KAFKA_BOOTSTRAP_SERVERS`  | Servidores Kafka        | `["localhost:9092"]`         |
| `KAFKA_ENABLE`             | Habilitar Kafka         | `true`                       |
| `LOG_LEVEL`                | Nivel de logging        | `"INFO"`                     |

### üèóÔ∏è Arquitectura de Servicios

```mermaid
graph TB
    A[FastAPI App] --> B[Chat Service]
    B --> C[LLM Service]
    B --> D[Embedding Service]
    B --> E[Vector DB Service]
    B --> F[Kafka Service]
    C --> G[Ollama]
    D --> G
    E --> H[ChromaDB]
    F --> I[Kafka Topics]
```

#### üîß Servicios Principales

1. **ChatService**: Orquestador central que coordina todos los servicios
2. **LLMService**: Maneja la comunicaci√≥n con Ollama para generaci√≥n de texto
3. **EmbeddingService**: Genera embeddings para documentos y consultas
4. **VectorDBService**: Gestiona ChromaDB para b√∫squeda sem√°ntica
5. **KafkaService**: Distribuye mensajes a trav√©s de Apache Kafka

### üöÄ Scripts de Desarrollo

```powershell
# Configuraci√≥n autom√°tica del entorno
python utils.py setup

# Verificar estado de todos los servicios
python utils.py check

# Iniciar servidor en modo desarrollo
python utils.py start --reload

# Ejecutar diagn√≥stico completo
python diagnose.py

# Probar cliente de ejemplo
python client_example.py

# Verificar integraci√≥n Kafka
python verify_kafka.py
```

## üîß Resoluci√≥n de Problemas

### üö® Diagn√≥stico Autom√°tico

Ejecuta primero el script de diagn√≥stico para identificar problemas:

```powershell
# Diagn√≥stico completo del sistema
python diagnose.py

# Verificaci√≥n espec√≠fica de Kafka
python verify_kafka.py

# Verificaci√≥n general de servicios
python utils.py check
```

### ‚ùå Problemas Comunes

#### 1. **Error: "BaseSettings has been moved to pydantic-settings"**

```powershell
# Instalar pydantic-settings
pip install pydantic-settings

# O reinstalar todas las dependencias
pip install -r requirements.txt --force-reinstall

# Verificar instalaci√≥n
python -c "from pydantic_settings import BaseSettings; print('‚úÖ OK')"
```

#### 2. **Kafka no se conecta**

```powershell
# Verificar estado de Docker
docker-compose ps

# Ver logs de Kafka
docker-compose logs kafka

# Reiniciar servicios
docker-compose restart

# Verificar conectividad
python verify_kafka.py
```

#### 3. **Ollama no disponible**

```powershell
# Verificar que Ollama est√© ejecut√°ndose
ollama list

# Descargar modelos si faltan
ollama pull phi3:3.8b
ollama pull nomic-embed-text

# Verificar conectividad
curl http://localhost:11434/api/tags
```

#### 4. **Puerto en uso**

```powershell
# Cambiar puerto en .env
echo "PORT=8001" >> .env

# O especificar puerto diferente
python utils.py start --port 8001

# Verificar qu√© proceso usa el puerto
netstat -ano | findstr :8000
```

#### 5. **Problemas de permisos**

```powershell
# Verificar permisos de directorios
# Asegurar que el usuario tiene acceso a:
# - chroma_db/
# - logs/
# - .env

# Crear directorios si no existen
mkdir chroma_db
mkdir logs
```

### üìä Monitoreo y Logs

#### Ubicaci√≥n de Logs

- **Consola**: Nivel INFO
- **Archivo**: `logs/app.log` (Nivel DEBUG)
- **Docker Compose**: `docker-compose logs`

#### Health Checks

```powershell
# Estado general
curl http://localhost:8000/health/

# Estado de Kafka espec√≠ficamente
curl http://localhost:8000/health/kafka

# Informaci√≥n de modelos
curl http://localhost:8000/health/models

# Estad√≠sticas de documentos
curl http://localhost:8000/documents/stats
```

### üîç Comandos de Depuraci√≥n

```powershell
# Ver todos los procesos relacionados
netstat -ano | findstr :8000
netstat -ano | findstr :9092

# Verificar Docker
docker ps
docker-compose ps

# Logs detallados
docker-compose logs -f kafka
docker-compose logs -f kafka-ui

# Limpiar datos de Kafka (si es necesario)
docker-compose down -v
docker-compose up -d
```

## üîÑ Flujo de Trabajo T√≠pico

### üöÄ Inicio R√°pido (5 minutos)

```powershell
# 1. Clonar y navegar
git clone [repo-url]
cd python-kafka/server-python

# 2. Configurar entorno
python -m venv .venv
.venv\Scripts\activate
pip install -r requirements.txt

# 3. Preparar Ollama
ollama pull phi3:3.8b
ollama pull nomic-embed-text

# 4. Iniciar Kafka (opcional)
cd ..
docker-compose up -d
cd server-python

# 5. Iniciar servidor
python run.py
```

### üí° Ejemplos de Uso

#### Conversaci√≥n B√°sica

```powershell
# POST /chat/
{
  "message": "Explica qu√© es machine learning",
  "use_context": false,
  "temperature": 0.7
}
```

#### Conversaci√≥n con Contexto

```powershell
# 1. A√±adir documento
# POST /documents/
{
  "content": "Machine Learning es una rama de la IA...",
  "conversation_id": "conv_001"
}

# 2. Chat con contexto
# POST /chat/
{
  "message": "¬øPuedes profundizar m√°s sobre ML?",
  "use_context": true,
  "conversation_id": "conv_001"
}
```

#### Streaming en Tiempo Real

```powershell
# POST /chat/stream
{
  "message": "Escribe un art√≠culo sobre IA",
  "use_context": true
}
# Respuesta llega por chunks en tiempo real
```

## ü§ù Contribuci√≥n

### üìù C√≥mo Contribuir

1. **Fork** el repositorio
2. **Crear** rama de feature (`git checkout -b feature/nueva-funcionalidad`)
3. **Commit** los cambios (`git commit -am 'A√±adir nueva funcionalidad'`)
4. **Push** a la rama (`git push origin feature/nueva-funcionalidad`)
5. **Crear** Pull Request

### üß™ Testing

```powershell
# Ejecutar pruebas b√°sicas
python client_example.py

# Pruebas de integraci√≥n
python test_integration.py

# Verificar Kafka
python verify_kafka.py

# Diagn√≥stico completo
python diagnose.py
```

### üìã Checklist para Contribuir

- [ ] C√≥digo sigue las convenciones del proyecto
- [ ] Documentaci√≥n actualizada
- [ ] Tests pasan correctamente
- [ ] No se rompe la funcionalidad existente
- [ ] Variables de entorno documentadas

## üìû Soporte y Comunidad

### üîó Enlaces √ötiles

- **Documentaci√≥n FastAPI**: https://fastapi.tiangolo.com/
- **LangChain Docs**: https://python.langchain.com/
- **Ollama GitHub**: https://github.com/ollama/ollama
- **Apache Kafka**: https://kafka.apache.org/
- **ChromaDB**: https://docs.trychroma.com/

### üìä Informaci√≥n del Sistema

- **Versi√≥n**: 1.0.0
- **Python**: 3.11+
- **Licencia**: MIT
- **√öltima actualizaci√≥n**: Julio 2025

---

## üìÑ Resumen de Comandos

```powershell
# Instalaci√≥n y configuraci√≥n
python -m venv .venv && .venv\Scripts\activate
pip install -r requirements.txt
copy .env.example .env

# Preparar modelos
ollama pull phi3:3.8b && ollama pull nomic-embed-text

# Iniciar servicios
docker-compose up -d  # Kafka (opcional)
python run.py         # Servidor IA

# Verificaci√≥n
python utils.py check
python verify_kafka.py
curl http://localhost:8000/health/

# Desarrollo
python utils.py start --reload
python diagnose.py
python client_example.py
```

**üéâ ¬°El sistema est√° listo para usar! Visita http://localhost:8000/docs para comenzar.**
